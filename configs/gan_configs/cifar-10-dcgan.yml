gan_config:
  dp: true
  dataset: 
    name: cifar10
    params: {}
  train_transform:
    Normalize:
      mean: &mean [0.5, 0.5, 0.5]
      std: &std [0.5, 0.5, 0.5]
  prior: normal
  eval: true
  generator:
    name: DCGANGenerator
    params:
      ngpu: 1
      mean: *mean
      std: *std
    ckpt_path: log/dumb_feature_PriorTarget_train/dcgan_0.01_44/checkpoints/g_200.pth #checkpoints/dcgan/DCGAN_G_CIFAR_199.pth
  discriminator:
    name: DCGANDiscriminator
    params:
      ngpu: 1
      mean: *mean
      std: *std
    ckpt_path: log/dumb_feature_PriorTarget_train/dcgan_0.01_44/checkpoints/d_200.pth #checkpoints/dcgan/DCGAN_D_CIFAR_199.pth
  thermalize:
    true: {}
    false:
      log_norm_const: 0.21158193327342437
      lipschitz_const: 15.621315625
      fake_score: -4.945679950714111
      real_score: &real_score -0.43365247461013495
      mean_score: -2.689666212662123


train_batch_size: &train_batch_size 64 #256 #128
n_epochs: &n_epochs 200 #150 #0
criterion_g: &criterion_g
  name: JensenNSLoss
criterion_d: &criterion_d
  name: JensenNSLoss
optimizer_g: &optimizer_g
  name: Adam
  params:
    lr: &g_lr 0.0003
    betas: [0.5, 0.999]
optimizer_d: &optimizer_d
  name: Adam
  params:
    lr: 0.0003
    betas: [0.5, 0.999]
trainer_kwargs: &trainer_kwargs
  n_dis: 1
  sample_size: 10000 #512 #5000
  grad_acc_steps: 1
  # sample_steps: &sample_steps 1
  sample_steps: &sample_steps 2 #4
  alpha: 300
