{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "import ruamel.yaml as yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import maxent_gan.models\n",
    "from maxent_gan.models import MMCSNDiscriminator, MMCSNGenerator\n",
    "from maxent_gan.models.utils import load_gan\n",
    "from maxent_gan.utils.general_utils import DotConfig, CONFIGS_DIR, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_config = yaml.round_trip_load(Path(CONFIGS_DIR, 'gan_configs', 'celeba-sngan-mmc.yml').open('r'))\n",
    "config = DotConfig(raw_config['gan_config'])\n",
    "\n",
    "gen, dis = load_gan(config, device, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile \n",
    "import gdown\n",
    "import torch\n",
    "# from natsort import natsorted\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "## Setup\n",
    "# Number of gpus available\n",
    "ngpu = 1\n",
    "device = torch.device('cuda:0' if (\n",
    "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
    "\n",
    "## Fetch data from Google Drive \n",
    "# Root directory for the dataset\n",
    "data_root = '../data/celeba'\n",
    "# Path to folder with the dataset\n",
    "dataset_folder = f'{data_root}/img_align_celeba'\n",
    "# URL for the CelebA dataset\n",
    "url = 'https://drive.google.com/uc?id=1cNIac61PSA_LqDFYFUeyaQYekYPc75NH'\n",
    "# Path to download the dataset to\n",
    "download_path = f'{data_root}/img_align_celeba.zip'\n",
    "\n",
    "# Create required directories \n",
    "if not os.path.exists(data_root):\n",
    "  os.makedirs(data_root)\n",
    "  os.makedirs(dataset_folder)\n",
    "\n",
    "# Download the dataset from google drive\n",
    "# gdown.download(url, download_path, quiet=False)\n",
    "\n",
    "# # Unzip the downloaded file \n",
    "# with zipfile.ZipFile(download_path, 'r') as ziphandler:\n",
    "#   ziphandler.extractall(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "        root_dir (string): Directory with all the images\n",
    "        transform (callable, optional): transform to be applied to each image sample\n",
    "      \"\"\"\n",
    "      # Read names of images in the root directory\n",
    "      image_names = os.listdir(root_dir)\n",
    "\n",
    "      self.root_dir = root_dir\n",
    "      self.transform = transform \n",
    "      self.image_names = image_names #natsorted(image_names)\n",
    "\n",
    "    def __len__(self): \n",
    "      return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      # Get the path to the image \n",
    "      img_path = os.path.join(self.root_dir, self.image_names[idx])\n",
    "      # Load image and convert it to RGB\n",
    "      img = Image.open(img_path).convert('RGB')\n",
    "      # Apply transformations to the image\n",
    "      if self.transform:\n",
    "        img = self.transform(img)\n",
    "\n",
    "      return img\n",
    "\n",
    "## Load the dataset \n",
    "# Path to directory with all the images\n",
    "img_folder = f'{dataset_folder}/img_align_celeba'\n",
    "# Spatial size of training images, images are resized to this size.\n",
    "image_size = 64\n",
    "# Transformations to be applied to each individual image sample\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                          std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "# Load the dataset from file and apply transformations\n",
    "celeba_dataset = CelebADataset(img_folder, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ea2d8a57f27bd43233272132454accb238a33b1e75d3ecbecd249b301daf972"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('soul2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
